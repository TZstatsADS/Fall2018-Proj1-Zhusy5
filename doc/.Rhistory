39.94/2
283.25/2
10.88/2
-63.57/2
-15/2
7.63/2
-2.24/2
-22/2
-800
18.94/2
-18.71/2
103.25/2
-20
-3.79/2
-90.5/2
a = c(51/2 ,
3.49/2 ,
35.24/2 ,
-8,
-20.3,
4.99,
-1.5/2,
8.99/2,
7.18/2,
-9/2,
4.99/2,
5/2,
10/2,
39.94/2,
283.25/2,
10.88/2,
-63.57/2,
-15/2,
7.63/2,
-2.24/2,
-22/2,
-800,
18.94/2,
-18.71/2,
103.25/2,
-20,
-3.79/2,
-90.5/2)
a
sum(a)
sum(a)
88593.16
31 + 18.47 + 7.99 + 192 - 78.28
setwd("~/Documents/Github/ADS/Fall2018-Proj1-Zhusy5/doc")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(DT)
library(tm)
hm_data <- read.csv("../data/cleaned_hm.csv")
datatable(head(hm_data[which(hm_data$reflection_period == "3m"), ], 5))
limit_words <- c('happy', 'day', 'got', 'went', 'today', 'made', 'one', 'two', 'time', 'last', 'first', 'going', 'getting', 'took', 'found', 'lot', 'really', 'saw', 'see', 'month', 'week', 'day', 'yesterday', 'year', 'ago', 'now', 'still', 'since', 'something', 'great', 'good', 'long', 'thing', 'toi', 'without', 'yesteri', '2s', 'toand', 'ing')
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c(limit_words, character(0))) %>%
tm_map(stripWhitespace)
tdm_modi<-TermDocumentMatrix(corpus) #Creates a TDM
TDM1<-as.matrix(tdm_modi) #Convert this into a matrix format
dim(tdm_modi)
Sys.setenv("R_MAX_VSIZE" = 8e9)
TDM1<-as.matrix(tdm_modi) #Convert this into a matrix format
Sys.getenv("R_MAX_SIZE")
Sys.getenv("R_MAX_SIZE")
Sys.setenv("R_MAX_SIZE" = 10e10)
Sys.getenv("R_MAX_SIZE")
TDM1<-as.matrix(tdm_modi) #Convert this into a matrix format
TDM1<-as.matrix(tdm_modi) #Convert this into a matrix format
write.csv("test_tdm.csv", tdm_modi)
names(tdm_modi)
View(tdm_modi)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
install.packages("wordcloud")
library(wordcloud)
wordcloud(corpus, max.words = 20,random.color = TRUE,random.order=TRUE)
limit_words <- c('happy', 'day', 'got', 'went', 'today', 'made', 'one', 'two', 'time', 'last', 'first', 'going', 'getting', 'took', 'found', 'lot', 'really', 'saw', 'see', 'month', 'week', 'day', 'yesterday', 'year', 'ago', 'now', 'still', 'since', 'something', 'great', 'good', 'long', 'thing', 'toi', 'without', 'yesteri', '2s', 'toand', 'ing')
corpus <- tm_map(corpus, removeWords,
c('happy', 'day', 'got', 'went', 'today', 'made', 'one', 'two', 'time', 'last', 'first', 'going', 'getting', 'took', 'found', 'lot', 'really', 'saw', 'see', 'month', 'week', 'day', 'yesterday', 'year', 'ago', 'now', 'still', 'since', 'something', 'great', 'good', 'long', 'thing', 'toi', 'without', 'yesteri', '2s', 'toand', 'ing'))
wordcloud(words = corpus, min.freq = 1,
max.words=20, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(corpus, max.words = 20,random.color = TRUE,random.order=TRUE)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
View(corpus)
names(corpus)
# wordcloud(words = corpus, min.freq = 1,
#           max.words=20, random.order=FALSE, rot.per=0.35,
#           colors=brewer.pal(8, "Dark2"))
wordcloud(corpus, max.words = 20,random.color = TRUE,random.order=TRUE)
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(stripWhitespace)
corpus <- tm_map(corpus, removeWords,
c('happy', 'day', 'got', 'went', 'today', 'made', 'one', 'two', 'time', 'last', 'first', 'going', 'getting', 'took', 'found', 'lot', 'really', 'saw', 'see', 'month', 'week', 'day', 'yesterday', 'year', 'ago', 'now', 'still', 'since', 'something', 'great', 'good', 'long', 'thing', 'toi', 'without', 'yesteri', '2s', 'toand', 'ing', "had", "and", "was"))
# wordcloud(words = corpus, min.freq = 1,
#           max.words=20, random.order=FALSE, rot.per=0.35,
#           colors=brewer.pal(8, "Dark2"))
wordcloud(corpus, max.words = 200,random.color = TRUE,random.order=TRUE)
corpus <- tm_map(corpus, removeWords,
c('happy', 'day', 'got', 'went', 'today', 'made', 'one', 'two', 'time', 'last', 'first', 'going', 'getting', 'took', 'found', 'lot', 'really', 'saw', 'see', 'month', 'week', 'day', 'yesterday', 'year', 'ago', 'now', 'still', 'since', 'something', 'great', 'good', 'long', 'thing', 'toi', 'without', 'yesteri', '2s', 'toand', 'ing', "had", "and", "was","ago","yesterday","lot","today","months","month", "happier","happiest","last","week","past"))
# wordcloud(words = corpus, min.freq = 1,
#           max.words=20, random.order=FALSE, rot.per=0.35,
#           colors=brewer.pal(8, "Dark2"))
wordcloud(corpus, max.words = 200,random.color = TRUE,random.order=TRUE)
Sys.setenv("R_MAX_VSIZE" = 1e12)
library(SnowballC)
library(RColorBrewer)
library(wordcloud)
# wordcloud(words = corpus, min.freq = 1,
#           max.words=20, random.order=FALSE, rot.per=0.35,
#           colors=brewer.pal(8, "Dark2"))
wordcloud(corpus, max.words = 200,random.color = TRUE,random.order=TRUE)
corpus_purchase <- tt_map(grep, pattern = "buy")
library(tidyverse)
library(data.table)
library(DT)
library(tm)
corpus_purchase <- tt_map(corpus, grep, pattern = "buy")
corpus_purchase <- tm_map(corpus, grep, pattern = "buy")
corpus_purchase_selection <- sapply(hm_data$cleaned_hm, grep, pattern = "buy")
head(corpus_purchase_selection)
corpus_purchase_selection <- simplify2array(sapply(hm_data$cleaned_hm, grep, pattern = "buy"))
head(corpus_purchase_selection)
corpus_purchase_selection <- simplify2array(sapply(hm_data$cleaned_hm, grep, pattern = "buy"))
head(corpus_purchase_selection)
corpus_purchase_selection <- unlist(simplify2array(sapply(hm_data$cleaned_hm, grep, pattern = "buy")))
head(corpus_purchase_selection)
names((sapply(hm_data$cleaned_hm, grep, pattern = "buy"))
)
head(corpus_purchase_selection)
corpus_purchase_selection <- ((sapply(hm_data$cleaned_hm, grep, pattern = "buy"))
)
head(corpus_purchase_selection)
head(corpus_purchase_selection) == ""
as.numeric(head(corpus_purchase_selection))
corpus_purchase_selection <- which(as.numeric(head(corpus_purchase_selection)) == 1)
corpus_purchase_selection <- which(as.numeric(head(corpus_purchase_selection)) != NA)
head(corpus_purchase_selection)
corpus_purchase_selection <- which(as.numeric(sapply(hm_data$cleaned_hm, grep, pattern = "buy")) != NA)
corpus_purchase_selection <- (as.numeric(sapply(hm_data$cleaned_hm, grep, pattern = "buy")) != NA)
table(corpus_purchase_selection)
corpus_purchase_selection <- sapply(hm_data$cleaned_hm, grep, pattern = "buy")
View(corpus_purchase_selection)
as.numeric(corpus_purchase_selection[[61]])
extract_index <- function(one_list_element){
if (as.numeric(one_list_element) == 1){
return(names(one_list_element))
}
else {
return(NA)
}
}
corpus_purchase_selection <- lapply(corpus_purchase_selection, extract_index)
extract_index <- function(one_list_element){
if (length(as.numeric(one_list_element)) != 0){
return(names(one_list_element))
}
else {
return(NA)
}
}
corpus_purchase_selection <- lapply(corpus_purchase_selection, extract_index)
head(corpus_purchase_selection)
corpus_purchase_selection <- sapply(corpus_purchase_selection, extract_index)
extract_index <- function(one_list_element){
if (length(as.numeric(one_list_element)) != 0){
return(names(one_list_element))
}
else {
return(NA)
}
}
corpus_purchase_selection <- sapply(corpus_purchase_selection, extract_index)
head(unlist(corpus_purchase_selection))
(unlist(corpus_purchase_selection))[61]
unlist(corpus_purchase_selection)[61]
(corpus_purchase_selection)[61]
corpus_purchase_selection[61]
extract_index <- function(one_list_element){
if (length(as.numeric(one_list_element)) != 0){
return(1)
}
else {
return(NA)
}
}
corpus_purchase_selection <- sapply(corpus_purchase_selection, extract_index)
corpus_purchase_selection[61]
corpus_purchase_selection <- sapply(hm_data$cleaned_hm, grep, pattern = "buy")
corpus_purchase_selection[61]
names(corpus_purchase_selection[61])
length(as.numeric(corpus_purchase_selection[61]))
length(as.numeric(corpus_purchase_selection[1]))
(as.numeric(corpus_purchase_selection[1]))
(as.numeric(corpus_purchase_selection[61]))
extract_index <- function(one_list_element){
if ((as.numeric(one_list_element)) == 1){
return(1)
}
else {
return(NA)
}
}
corpus_purchase_selection2 <- sapply(corpus_purchase_selection, extract_index)
extract_index <- function(one_list_element){
if (length(as.numeric(one_list_element)) == 1){
return(1)
}
else {
return(NA)
}
}
corpus_purchase_selection2 <- sapply(corpus_purchase_selection, extract_index)
corpus_purchase_selection2 <- lapply(corpus_purchase_selection, extract_index)
View(corpus_purchase_selection2)
View(corpus_purchase_selection2)
corpus_purchase_selection2 <- apply(corpus_purchase_selection, extract_index)
extract_index <- function(one_list_element){
if (length(as.numeric(one_list_element)) == 1){
return(1)
}
else {
return(NA)
}
}
corpus_purchase_selection2 <- apply(corpus_purchase_selection, 1, extract_index)
corpus_purchase_selection[[61]]
v = c()
for (i in 1:length(corpus_purchase_selection)){
if(corpus_purchase_selection[[i]] == 1){
v = c(v, i)
}
}
i
corpus_purchase_selection[[i]]
corpus_purchase_selection[[i]] == 1
for (i in 1:length(corpus_purchase_selection)){
if(corpus_purchase_selection[[i]] == 1){
v = c(v, i)
}
print(i)
}
v = c()
for (i in 1:length(corpus_purchase_selection)){
if(corpus_purchase_selection[[i]] == 1){
v = c(v, i)
}
print(i)
}
for (i in 1:length(corpus_purchase_selection)){
if(corpus_purchase_selection[i] == 1){
v = c(v, i)
}
print(i)
}
(corpus_purchase_selection[i] == 1)
i
for (i in 1:length(corpus_purchase_selection)){
if(length(corpus_purchase_selection[i] == 1) == 1){
v = c(v, i)
}
print(i)
}
v
length(corpus_purchase_selection[i] == 1)
i = 1
length(corpus_purchase_selection[i] == 1)
length(NA)
length(corpus_purchase_selection[i] == 1)
((corpus_purchase_selection[i] == 1) != NA)
((corpus_purchase_selection[61] == 1) != NA)
((corpus_purchase_selection[[61]] == 1) != NA)
(corpus_purchase_selection[[61]] == 1)
(corpus_purchase_selection[[61]] == 1) == MA
(corpus_purchase_selection[[61]] == 1) == NA
(as.numeric(corpus_purchase_selection[i] == 1) != NA)
(as.numeric(corpus_purchase_selection[61] == 1) != NA)
as.numeric(corpus_purchase_selection[61] == 1)
as.numeric(corpus_purchase_selection[61] == 1) == NA
as.numeric(corpus_purchase_selection[61] == 1)
length(as.numeric(corpus_purchase_selection[61] == 1))
as.numeric(corpus_purchase_selection[61] == 1) == 1
as.numeric(corpus_purchase_selection[1] == 1) == 1
as.numeric(corpus_purchase_selection[1] == 1) != 1
test = as.numeric(corpus_purchase_selection[1] == 1) != 1
test == NA
is.na(test)
v = c()
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
return(NA)
}
if(test){
v = c(v, i)
}
}
v = c()
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
return(NA)
}
if(test){
v = c(v, i)
}
}
i = 1
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
print("NA")
}
if(test){
v = c(v, i)
}
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
print("NA")
}
if(test){
v = c(v, i)
}
}
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
print("NA")
}
else{
v = c(v, i)
}
}
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
}
else{
v = c(v, i)
}
}
corpus_purchase_selection <- sapply(hm_data$cleaned_hm, grep, pattern = "buy || purchase")
v = c()
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
}
else{
v = c(v, i)
}
}
corpus_purchase_selection <- sapply(hm_data$cleaned_hm, grep, pattern = "buy")
corpus_purchase_selection <- sapply(hm_data$cleaned_hm, grep, pattern = "buy")
v = c()
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
}
else{
v = c(v, i)
}
}
hm_data$cleaned_hm[61]
hm_data <- read.csv("../data/cleaned_hm.csv", stringsAsFactors = F)
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c(limit_words, character(0))) %>%
tm_map(stripWhitespace)
corpus_purchase_selection <- sapply(hm_data$cleaned_hm, grep, pattern = "buy")
v = c()
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
}
else{
v = c(v, i)
}
}
install.packages("text2vec")
install.packages("magrittr")
install.packages("magrittr")
library(text2vec)
library(magrittr)
prep_fun = tolower
tok_fun = word_tokenizer
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(hm_data$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = hm_data$hmid,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vectorizer = vocab_vectorizer(vocab)
t1 = Sys.time()
dtm_train = create_dtm(it_train, vectorizer)
dtm_train = create_dtm(it_train, vectorizer)
print(difftime(Sys.time(), t1, units = 'sec'))
dim(dtm_train)
identical(rownames(dtm_train), hm_data$hmid)
rowname(dtm_train)
rownames(dtm_train)
dim(dtm_train)
identical(rownames(dtm_train), hm_data$hmid)
head(vocab)
dim(vocab)
head(hm_data$hmid)
head(rownames(dtm_train))
identical(as.numeric(rownames(dtm_train)), hm_data$hmid)
identical(as.numeric(rownames(dtm_train)), hm_data$hmid)
as.numeric(rownames(dtm_train))
clear
table(as.numeric(rownames(dtm_train)) - hm_data$hmid)
identical(as.numeric(rownames(dtm_train)), hm_data$hmid)
library(glmnet)
install.packages("glmnet")
library(glmnet)
NFOLDS = 4
load("lalala.rdata")
names(hmdemo_data)
hmdemo_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
hmid,
cleaned_hm,
predicted_category,
gender,
marital,
parenthood,
age,
country,
reflection_period) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m"))
prep_fun = tolower
tok_fun = word_tokenizer
it_train = itoken(hmdemo_data$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = hm_data$hmid,
progressbar = TRUE)
it_train = itoken(hmdemo_data$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = hmdemo_data$hmid,
progressbar = TRUE)
write.csv("hm_data_withdemo.csv", hmdemo_data)
write.csv("hm_data_withdemo.csv", hmdemo_data)
write.csv(hmdemo_data, "hm_data_withdemo.csv")
hmdemo_data <- read.csv("hm_data_withdemo.csv", stringsAsFactors = F)
it_train = itoken(hmdemo_data$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = hmdemo_data$hmid,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vectorizer = vocab_vectorizer(vocab)
t1 = Sys.time()
dtm_train = create_dtm(it_train, vectorizer)
dtm_train = create_dtm(it_train, vectorizer)
print(difftime(Sys.time(), t1, units = 'sec'))
dim(dtm_train)
# identical(as.numeric(rownames(dtm_train)), hm_data$hmid)
table(as.numeric(rownames(dtm_train)) - hmdemo_data$hmid)
library(glmnet)
NFOLDS = 4
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = hmdemo_data$gender,
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
plot(glmnet_classifier)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
library(DT)
library(tm)
hm_data <- read.csv("../data/cleaned_hm.csv", stringsAsFactors = F)
datatable(head(hm_data[which(hm_data$reflection_period == "3m"), ], 5))
limit_words <- c('happy', 'day', 'got', 'went', 'today', 'made', 'one', 'two', 'time', 'last', 'first', 'going', 'getting', 'took', 'found', 'lot', 'really', 'saw', 'see', 'month', 'week', 'day', 'yesterday', 'year', 'ago', 'now', 'still', 'since', 'something', 'great', 'good', 'long', 'thing', 'toi', 'without', 'yesteri', '2s', 'toand', 'ing')
corpus <- VCorpus(VectorSource(hm_data$cleaned_hm))%>%
tm_map(content_transformer(tolower))%>%
tm_map(removePunctuation)%>%
tm_map(removeNumbers)%>%
tm_map(removeWords, c(limit_words, character(0))) %>%
tm_map(stripWhitespace)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
