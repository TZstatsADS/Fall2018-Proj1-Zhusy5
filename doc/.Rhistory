dim(dtm_train)
prep_fun = tolower
tok_fun = word_tokenizer
#hmdemo_data <- read.csv("hm_data_withdemo.csv", stringsAsFactors = F)
it_train = itoken(train$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$hmid,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vocab
vectorizer = vocab_vectorizer(vocab)
t1 = Sys.time()
dtm_train = create_dtm(it_train, vectorizer)
print(difftime(Sys.time(), t1, units = 'sec'))
dim(dtm_train)
library(glmnet)
NFOLDS = 4
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = train$marital,
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
plot(glmnet_classifier)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
# Note that most text2vec functions are pipe friendly!
it_test = test$review %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$id, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
dtm_test
dtm_test
# Note that most text2vec functions are pipe friendly!
it_test = test$marital %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$hmid, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$sentiment, preds)
# Note that most text2vec functions are pipe friendly!
it_test = test$marital %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$hmid, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$marital, preds)
preds
# Note that most text2vec functions are pipe friendly!
it_test = test$marital %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$hmid, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$marital, preds)
library(text2vec)
library(data.table)
library(magrittr)
hmdemo_data <- hmdemo_data[hmdemo_data$marital %in% c("single", "married"), ]
hm_marry <- hmdemo_data[, c("hmid", "cleaned_hm", "marital")]
setDT(hm_marry)
setkey(hm_marry, hmid)
set.seed(2017L)
all_ids = hm_marry$hmid
train_ids = sample(all_ids, 76359)
test_ids = setdiff(all_ids, train_ids)
train = hm_marry[J(train_ids)]
test = hm_marry[J(test_ids)]
prep_fun = tolower
tok_fun = word_tokenizer
#hmdemo_data <- read.csv("hm_data_withdemo.csv", stringsAsFactors = F)
it_train = itoken(train$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$hmid,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vocab
vectorizer = vocab_vectorizer(vocab)
t1 = Sys.time()
dtm_train = create_dtm(it_train, vectorizer)
print(difftime(Sys.time(), t1, units = 'sec'))
dim(dtm_train)
# identical(as.numeric(rownames(dtm_train)), hm_data$hmid)
table(as.numeric(rownames(dtm_train)) - train$hmid)
library(glmnet)
NFOLDS = 4
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = train$marital,
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
plot(glmnet_classifier)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
# Note that most text2vec functions are pipe friendly!
it_test = test$marital %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$hmid, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$marital, preds)
# Note that most text2vec functions are pipe friendly!
it_test = test$cleaned_hm %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$hmid, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$marital, preds)
preds
head
head(preds)
head(test$marital)
hm_marry
head(test$marital)
head(preds)
head(movie_review)
head(movie_review,1)
head(hm_marry)
num <- function(ele) {
if (ele = "married") {
if (ele == "married") {
return(1)
} else {
return(0)
}
num <- function(ele) {
if (ele == "married") {
return(1)
} else {
return(0)
}
}
sapply(hm_marry$marital, num)
head(hm_marry)
sapply(hm_marry$marital, num)
head(sapply(hm_marry$marital, num)
)
num <- function(ele) {
if (ele == "married") {
ele = 1
} else {
ele = 0
}
}
sapply(hm_marry$marital, num)
head(sapply(hm_marry$marital, num)
)
num("single")
a <- "single"
num(a)
a
num <- function(ele) {
if (ele == "married") {
return(ele = 1)
} else {
return(ele = 0)
}
}
num(a)
sapply(hm_marry$marital, num)
num(a)
a <- "married"
num(a)
sapply(hm_marry$marital, num)
tapply(hm_marry$marital, num)
apply(hm_marry$marital, 2,  num)
apply(hm_marry$marital, 2, num)
hm_marry$marital
class(hm_marry$marital
)
is.array(hm_marry$marital)
is.data.frame(hm_marry$marital)
is.data.frame(hm_marry)
is.data.frame(hm_marry[, 3])
apply(hm_marry[, 3], 2,  num)
hm_marry$marital
hm_marry[, 3]
num(hm_marry$marital[1])
for (i in length(hm_marry$marital)) {
if (hm_marry$marital[i] == "married") {
hm_marry$marital[i] = 1
} else {
hm_marry$marital[i] = 0
}
}
hm_marry$marital
hmdemo_data <- hmdemo_data[hmdemo_data$marital %in% c("single", "married"), ]
hm_marry <- hmdemo_data[, c("hmid", "cleaned_hm", "marital")]
for (i in length(hm_marry$marital)) {
if (hm_marry$marital[i] == "married") {
hm_marry$marital[i] = 1
} else {
hm_marry$marital[i] = 0
}
}
head(hm_marry$marital)
hm_marry$marital[i]
hm_marry$marital
as.numeric(hm_marry$marital)
as.factor(hm_marry$marital)
as.numeric(as.factor(hm_marry$marital))
as.numeric(as.factor(hm_marry$marital))
as.numeric(as.factor(hm_marry$marital)) - 1
as.numeric(as.factor(hm_marry$marital)) - 2
head(hm_marry$marital)
hm_marry$marital <- as.numeric(as.factor(hm_marry$marital)) - 2
head(hm_marry$marital)
library(text2vec)
library(data.table)
library(magrittr)
hmdemo_data <- hmdemo_data[hmdemo_data$marital %in% c("single", "married"), ]
hm_marry <- hmdemo_data[, c("hmid", "cleaned_hm", "marital")]
hm_marry$marital <- as.numeric(as.factor(hm_marry$marital)) - 2
setDT(hm_marry)
setkey(hm_marry, hmid)
set.seed(2017L)
all_ids = hm_marry$hmid
train_ids = sample(all_ids, 76359)
test_ids = setdiff(all_ids, train_ids)
train = hm_marry[J(train_ids)]
test = hm_marry[J(test_ids)]
prep_fun = tolower
tok_fun = word_tokenizer
#hmdemo_data <- read.csv("hm_data_withdemo.csv", stringsAsFactors = F)
it_train = itoken(train$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$hmid,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vocab
prep_fun = tolower
tok_fun = word_tokenizer
#hmdemo_data <- read.csv("hm_data_withdemo.csv", stringsAsFactors = F)
it_train = itoken(train$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$hmid,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vocab
vectorizer = vocab_vectorizer(vocab)
t1 = Sys.time()
dtm_train = create_dtm(it_train, vectorizer)
print(difftime(Sys.time(), t1, units = 'sec'))
dim(dtm_train)
# identical(as.numeric(rownames(dtm_train)), hm_data$hmid)
table(as.numeric(rownames(dtm_train)) - train$hmid)
library(glmnet)
NFOLDS = 4
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = train$marital,
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
plot(glmnet_classifier)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
# Note that most text2vec functions are pipe friendly!
it_test = test$cleaned_hm %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$hmid, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$marital, preds)
test$marital
hm_marry$marital
library(text2vec)
library(data.table)
library(magrittr)
hmdemo_data <- hmdemo_data[hmdemo_data$marital %in% c("single", "married"), ]
hm_marry <- hmdemo_data[, c("hmid", "cleaned_hm", "marital")]
hm_marry$marital <- as.numeric(as.factor(hm_marry$marital)) - 1
setDT(hm_marry)
setkey(hm_marry, hmid)
set.seed(2017L)
all_ids = hm_marry$hmid
train_ids = sample(all_ids, 76359)
test_ids = setdiff(all_ids, train_ids)
train = hm_marry[J(train_ids)]
test = hm_marry[J(test_ids)]
head(hm_marry$marital)
prep_fun = tolower
tok_fun = word_tokenizer
#hmdemo_data <- read.csv("hm_data_withdemo.csv", stringsAsFactors = F)
it_train = itoken(train$cleaned_hm,
preprocessor = prep_fun,
tokenizer = tok_fun,
ids = train$hmid,
progressbar = TRUE)
vocab = create_vocabulary(it_train)
vocab
vectorizer = vocab_vectorizer(vocab)
t1 = Sys.time()
dtm_train = create_dtm(it_train, vectorizer)
print(difftime(Sys.time(), t1, units = 'sec'))
library(glmnet)
NFOLDS = 4
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = train$marital,
family = 'binomial',
# L1 penalty
alpha = 1,
# interested in the area under ROC curve
type.measure = "auc",
# 5-fold cross-validation
nfolds = NFOLDS,
# high value is less accurate, but has faster training
thresh = 1e-3,
# again lower number of iterations for faster training
maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
# Note that most text2vec functions are pipe friendly!
it_test = test$cleaned_hm %>%
prep_fun %>% tok_fun %>%
# turn off progressbar because it won't look nice in rmd
itoken(ids = test$hmid, progressbar = FALSE)
dtm_test = create_dtm(it_test, vectorizer)
preds = predict(glmnet_classifier, dtm_test, type = 'response')[,1]
glmnet:::auc(test$marital, preds)
plot(glmnet_classifier)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
t1 = Sys.time()
vocab = create_vocabulary(it_train, ngram = c(1L, 2L))
print(difftime(Sys.time(), t1, units = 'sec'))
vocab = prune_vocabulary(vocab, term_count_min = 10,
doc_proportion_max = 0.5)
bigram_vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, bigram_vectorizer)
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = train[['sentiment']],
family = 'binomial',
alpha = 1,
type.measure = "auc",
nfolds = NFOLDS,
thresh = 1e-3,
maxit = 1e3)
vocab = prune_vocabulary(vocab, term_count_min = 10,
doc_proportion_max = 0.5)
bigram_vectorizer = vocab_vectorizer(vocab)
dtm_train = create_dtm(it_train, bigram_vectorizer)
t1 = Sys.time()
glmnet_classifier = cv.glmnet(x = dtm_train, y = train[['marital']],
family = 'binomial',
alpha = 1,
type.measure = "auc",
nfolds = NFOLDS,
thresh = 1e-3,
maxit = 1e3)
print(difftime(Sys.time(), t1, units = 'sec'))
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
install.packages("prettydoc")
library(reticulate)
library(prettydoc)
# use_python("/usr/local/bin/python3")
use_condaenv("tensorflow")	#Specify the name of a Conda environment.
knitr::knit_engines$set(python = reticulate::eng_python)
knitr::opts_chunk$set(echo = TRUE)
# Sys.setenv(python = '/anaconda3/envs/tensorflow/bin/python')
library(DT)
library(tidyverse)
library(tm)
library(glmnet)
hm_data <- read.csv(file="/Users/siyuzhu/Documents/Github/ADS/Fall2018-Proj1-Zhusy5/data/cleaned_hm.csv", header=TRUE)
library(reticulate)
library(prettydoc)
# use_python("/usr/local/bin/python3")
use_condaenv("tensorflow")	#Specify the name of a Conda environment.
knitr::knit_engines$set(python = reticulate::eng_python)
knitr::opts_chunk$set(echo = TRUE)
# Sys.setenv(python = '/anaconda3/envs/tensorflow/bin/python')
sum(is.null(hm_data$predicted_category))
category_sum1 <- as.data.frame(table(hm_data$predicted_category))
category_sum1
category_sum1 <- mutate(category_sum1, Prob = Freq / sum(category_sum1$Freq))
prob <- category_sum1$Prob
names(prob) <- c("achievement", "affection", "bonding", "enjoy_the_moment", "exercise", "leisure", "nature")
prob <- as.data.frame(prob)
names(prob) <- "whole_prob"
prob
library(ggplot2)
ggplot(category_sum1, aes(x = Var1, y = Freq)) +
geom_bar(fill = "#0073C2FF", stat = "identity") +
geom_text(aes(label = Freq), vjust = -0.3)
head(hm_data$predicted_category)
category_sum2 <- data.frame("category" = c("achievement", "affection", "self_origin"), "Freq" = c(category_sum1$Freq[category_sum1$Var1 == "achievement"], category_sum1$Freq[category_sum1$Var1 == "affection"] + category_sum1$Freq[category_sum1$Var1 == "bonding"], category_sum1$Freq[category_sum1$Var1 == "enjoy_the_moment"] + category_sum1$Freq[category_sum1$Var1 == "exercise"] + category_sum1$Freq[category_sum1$Var1 == "leisure"] + category_sum1$Freq[category_sum1$Var1 == "nature"]))
library(ggplot2)
ggplot(category_sum2, aes(x = category, y = Freq)) +
geom_bar(fill = "#0073C2FF", stat = "identity") +
geom_text(aes(label = Freq), vjust = -0.3)
library(dplyr)
demo_data <- read.csv(file="/Users/siyuzhu/Documents/Github/ADS/Fall2018-Proj1-Zhusy5/data/demographic.csv", header=TRUE)
hmdemo_data <- hm_data %>%
inner_join(demo_data, by = "wid") %>%
select(wid,
hmid,
cleaned_hm,
predicted_category,
gender,
marital,
parenthood,
age,
country,
reflection_period)
# datatable(head(hmdemo_data))
# for male
male_cate <- hmdemo_data[hmdemo_data$gender == "m", 4]
male_sum <- as.data.frame(table(male_cate))
male_sum <- mutate(male_sum, Prob = Freq / sum(male_sum$Freq))
prob$male_prob <- male_sum$Prob
# for female
female_cate <- hmdemo_data[hmdemo_data$gender == "f", 4]
female_sum <- as.data.frame(table(female_cate))
female_sum <- mutate(female_sum, Prob = Freq / sum(female_sum$Freq))
prob$female_prob <- female_sum$Prob
# for single
single_cate <- hmdemo_data[hmdemo_data$marital == "single", 4]
single_sum <- as.data.frame(table(single_cate))
single_sum <- mutate(single_sum, Prob = Freq / sum(single_sum$Freq))
prob$single_prob <- single_sum$Prob
# for marital
married_cate <- hmdemo_data[hmdemo_data$marital == "married", 4]
married_sum <- as.data.frame(table(married_cate))
married_sum <- mutate(married_sum, Prob = Freq / sum(married_sum$Freq))
prob$married_prob <- married_sum$Prob
# for nonparent
nonparent_cate <- hmdemo_data[hmdemo_data$parenthood == "n", 4]
nonparent_sum <- as.data.frame(table(nonparent_cate))
nonparent_sum <- mutate(nonparent_sum, Prob = Freq / sum(nonparent_sum$Freq))
prob$nonparent_prob <- nonparent_sum$Prob
# for parent
parent_cate <- hmdemo_data[hmdemo_data$parenthood == "y", 4]
parent_sum <- as.data.frame(table(parent_cate))
parent_sum <- mutate(parent_sum, Prob = Freq / sum(parent_sum$Freq))
prob$parent_prob <- parent_sum$Prob
prob <- t(prob)
prob
graph_data <- data.frame("sector" = rep(c("whole_prob", "male_prob", "female_prob", "single_prob", "married_prob", "nonparent_prob", "parent_prob"), 7),  "category" = rep(names(table(hmdemo_data$predicted_category)), each = 7), "freq" = c(as.numeric(prob[,1]), as.numeric(prob[,2]), as.numeric(prob[,3]), as.numeric(prob[,4]), as.numeric(prob[,5]), as.numeric(prob[,6]), as.numeric(prob[,7])))
graph_data2 <- data.frame(category = as.numeric(as.factor(graph_data$category)),
freq = graph_data$freq,
sector = graph_data$sector)
ggplot(graph_data2, aes(x=category, y=freq, fill=sector)) +
geom_area() +
scale_x_continuous(breaks=seq(1, 7, 1),
labels=names(table(graph_data$category)))
names(table(graph_data$category))
sector
graph_data
graph_data2
graph_data2$sector
ggplot(graph_data2, aes(x=category, y=freq, fill=sector)) +
geom_area() +
scale_x_continuous(breaks=seq(1, 7, 1),
labels=names(table(graph_data$category)))
count_purchase_hm <- function(data_subset){
pattern = "(buy) | (purchase) | (bought) | (perchased) | (shopping)"
corpus_purchase_selection <- sapply(data_subset$cleaned_hm, grep, pattern = pattern)
v = c()
for (i in 1:length(corpus_purchase_selection)){
test = (as.numeric(corpus_purchase_selection[i] == 1) != 1)
if(is.na(test)){
}
else{
v = c(v, i)
}
}
return(length(v))
}
m_shop <- count_purchase_hm(subset(hmdemo_data, marital == "married"))
s_shop <- count_purchase_hm(subset(hmdemo_data, marital == "single"))
m_f_shop <- count_purchase_hm(subset(hmdemo_data, marital == "married" & gender == "f"))
m_m_shop <- count_purchase_hm(subset(hmdemo_data, marital == "married" & gender == "m"))
s_f_shop <- count_purchase_hm(subset(hmdemo_data, marital == "single" & gender == "f"))
s_m_shop <- count_purchase_hm(subset(hmdemo_data, marital == "single" & gender == "m"))
data.frame(class = c("married", "single", "married_f", "married_male", "single_female", "single_male"), number = c(m_shop, s_shop, m_f_shop, m_m_shop, s_f_shop, s_m_shop))
data.frame(class = c("married", "single", "married_female", "married_male", "single_female", "single_male"), number = c(m_shop, s_shop, m_f_shop, m_m_shop, s_f_shop, s_m_shop))
data.frame(class = c("married", "single", "married_female", "married_male", "single_female", "single_male"), number = c(m_shop, s_shop, m_f_shop, m_m_shop, s_f_shop, s_m_shop))
glmnet:::auc(test$marital, preds)
print(paste("max AUC =", round(max(glmnet_classifier$cvm), 4)))
